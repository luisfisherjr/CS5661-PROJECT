{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "import keras\n",
    "from keras import models, layers, callbacks, constraints, backend, activations\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import datetime\n",
    "import pathlib\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "\n",
    "    # transform train\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test_scaled = scaler.transform(test)\n",
    "\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, y):\n",
    "    \n",
    "    # combine data back into single matrix for scaling\n",
    "    features_and_labels_scaled = np.append(X, y, axis=1)\n",
    "    features_and_labels = scaler.inverse_transform(features_and_labels_scaled)\n",
    "    \n",
    "    return features_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and ann_model to be used with sklearn wrapper\n",
    "def ann_model(features = 1,\n",
    "              output_size = 1,\n",
    "              batch_size = 1,\n",
    "              epochs = 1,\n",
    "              hidden_layers = [{'neurons': 50, 'dropout': 0.1 }],\n",
    "              activation = 'relu',\n",
    "              optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              noise = (False, 0.07),\n",
    "              metrics = ['accuracy'],\n",
    "              verbose = 0,\n",
    "             ):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    from keras.layers import Input, Dense\n",
    "    from keras.models import Model\n",
    "\n",
    "    # This returns a tensor\n",
    "    inputs = Input(shape=(784,))\n",
    "\n",
    "    # a layer instance is callable on a tensor, and returns a tensor\n",
    "    x = Dense(64, activation='relu')(inputs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    # This creates a model that includes\n",
    "    # the Input layer and three Dense layers\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \"\"\"\n",
    "              \n",
    "    # create sequenital model\n",
    "    \n",
    "    inputs = layers.Input(shape=(features,))\n",
    "    \n",
    "    count = 1\n",
    "    x = None\n",
    "    previous = inputs\n",
    "    \n",
    "    # makes every hidden layer\n",
    "    for i in range(len(hidden_layers)):\n",
    "\n",
    "        layer = hidden_layers[i]\n",
    "        \n",
    "        if noise[0]:\n",
    "            \n",
    "            x = layers.GaussianNoise(noise[1])(previous)\n",
    "            previous = x\n",
    "\n",
    "        x = layers.Dense(\n",
    "            units = layer['neurons'],\n",
    "            activation = activation,\n",
    "            name='ANN_hidden_layer_{}'.format(i + 1)\n",
    "        )(previous)\n",
    "        \n",
    "        x = layers.Dropout(\n",
    "            rate = layer['dropout']\n",
    "        )(x)\n",
    "        previous = x\n",
    "           \n",
    "    # makes output layer\n",
    "    outputs = layers.Dense(\n",
    "        units = output_size,\n",
    "        activation = 'softmax',\n",
    "        name = 'output_layer',\n",
    "    )(previous)\n",
    "    \n",
    "    model = models.Model(\n",
    "        inputs = inputs, \n",
    "        outputs = outputs\n",
    "    )\n",
    "      \n",
    "    model.compile(\n",
    "        loss = loss,\n",
    "        optimizer = optimizer,\n",
    "        metrics = metrics,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  if __name__ == '__main__':\n",
      "/home/luis/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.DataFrame.from_csv('../dataset/train.csv', index_col=None)\n",
    "test_dataset = pd.DataFrame.from_csv('../dataset/test.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split training into X_train, y_train & rename train_dataset into X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15120, 55), (15120, 7))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.get_dummies(train_dataset['Cover_Type'],  prefix='Cover_Type_').values\n",
    "X_train = train_dataset.drop('Cover_Type', axis=1).values\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565892, 55)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_dataset.values\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y_train[:, 0]\n",
    "# y.shape\n",
    "\n",
    "# # base_clf = \n",
    "# adaboost_clf = AdaBoostClassifier(\n",
    "# #     base_estimator = base_clf, \n",
    "#     n_estimators=200)\n",
    "# scores = cross_val_score(adaboost_clf, X_train, y)\n",
    "# scores.mean()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras ann test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = y_train.shape[1]\n",
    "features = X_train.shape[1]\n",
    "batch_size = 1\n",
    "epochs = 50\n",
    "hidden_layers = [{'neurons': 50, 'dropout': 0.1}]\n",
    "verbose = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = ann_model(\n",
    "    features = features,\n",
    "    output_size = output_size,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    hidden_layers = hidden_layers,\n",
    "#     activation = 'relu',\n",
    "#     optimizer = 'adam',\n",
    "#     loss = 'categorical_crossentropy',\n",
    "    noise = (False, 0.07),\n",
    "#     metrics = ['acc'],\n",
    "#     verbose = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaped = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1s - loss: 1.1538 - acc: 0.5567\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.8348 - acc: 0.6530\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.7804 - acc: 0.6741\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.7420 - acc: 0.6863\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.7091 - acc: 0.7036\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.6844 - acc: 0.7150\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.6677 - acc: 0.7177\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.6465 - acc: 0.7294\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.6320 - acc: 0.7331\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.6187 - acc: 0.7428\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.6096 - acc: 0.7446\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.5986 - acc: 0.7507\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.5924 - acc: 0.7534\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.5837 - acc: 0.7573\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.5777 - acc: 0.7573\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.5701 - acc: 0.7646\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.5644 - acc: 0.7662\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.5581 - acc: 0.7667\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.5537 - acc: 0.7714\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.5489 - acc: 0.7705\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.5448 - acc: 0.7697\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.5396 - acc: 0.7746\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.5315 - acc: 0.7770\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.5305 - acc: 0.7810\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.5286 - acc: 0.7801\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.5232 - acc: 0.7826\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.5205 - acc: 0.7831\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.5220 - acc: 0.7823\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.5140 - acc: 0.7864\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.5127 - acc: 0.7866\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.5096 - acc: 0.7868\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.5063 - acc: 0.7912\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.5062 - acc: 0.7913\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.5058 - acc: 0.7894\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.5006 - acc: 0.7876\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.5042 - acc: 0.7909\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.4972 - acc: 0.7919\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.4955 - acc: 0.7923\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.4940 - acc: 0.7945\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.4920 - acc: 0.7970\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.4896 - acc: 0.7970\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.4877 - acc: 0.7989\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.4858 - acc: 0.7969\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.4902 - acc: 0.7958\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.4828 - acc: 0.7987\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.4794 - acc: 0.8015\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.4818 - acc: 0.7999\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.4816 - acc: 0.8003\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.4766 - acc: 0.8030\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.4775 - acc: 0.8003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a835b59e8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_test.fit(X_train, y_train, verbose = verbose, epochs = epochs)\n",
    "model_test.fit(X_train_scaled, y_train, verbose = verbose, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model_test.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9998540878295898, 0.0)\n",
      "(1.0, 1.7715477039630958e-15)\n",
      "(0.9964455962181091, 0.0)\n",
      "(0.9996896982192993, 0.0)\n",
      "(0.997796893119812, 0.0)\n",
      "(0.9992781281471252, 0.0)\n",
      "(1.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print('({}, {})'.format(max(y_hat[:,i]), min(y_hat[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8018518518518518"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, np.around(y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gridsearch and wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = ann_model, features = features, output_size = output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [100]\n",
    "\n",
    "l1 = [{'neurons': 50, 'dropout': 0.1}]\n",
    "l2 = [{'neurons': 100, 'dropout': 0.1}, {'neurons': 50, 'dropout': 0.1}]\n",
    "l3 = [{'neurons': 100, 'dropout': 0.1}, {'neurons': 50, 'dropout': 0.1}, {'neurons': 25, 'dropout': 0.1}]\n",
    "hidden_layers = [l1, l2, l3]\n",
    "\n",
    "noises = [(False, 0.07)]\n",
    "\n",
    "param_grid = dict(       \n",
    "                  epochs = epochs,\n",
    "                  hidden_layers = hidden_layers,\n",
    "#                   activation = activations,\n",
    "#                   optimizer = optimizers,\n",
    "#                   loss = losses,\n",
    "                  noise = noises,\n",
    "#                   metrics = metrics,\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = param_grid,\n",
    "    n_jobs = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.0330 - acc: 0.1589\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 3/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 4/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 5/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 6/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 7/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 8/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 10/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 12/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 13/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 14/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 15/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 16/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 17/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 18/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 19/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 20/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 21/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 35/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 37/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 38/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 39/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 40/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 42/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 50/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 54/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 55/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 56/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 57/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 58/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 59/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 60/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 63/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 64/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 65/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 66/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 67/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 68/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 69/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 70/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 72/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.1921e-07 - acc: 0.1590\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-02c4ce34cb46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-source-keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_train, y_train, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-source-keras]",
   "language": "python",
   "name": "conda-env-tf-source-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
